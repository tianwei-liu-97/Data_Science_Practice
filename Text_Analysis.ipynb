{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding Discussions 4 <br>\n",
    "Tianwei Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the texts as strings\n",
    "with open('aljazeera-khashoggi.txt', 'r') as file:\n",
    "    text_alja = file.read().replace('\\n', '')\n",
    "\n",
    "with open('bbc-khashoggi.txt', 'r') as file:\n",
    "    text_bbc = file.read().replace('\\n', '')\n",
    "\n",
    "with open('breitbart-khashoggi.txt', 'r') as file:\n",
    "    text_breit = file.read().replace('\\n', '')\n",
    "\n",
    "with open('fox-khashoggi.txt', 'r') as file:\n",
    "    text_fox = file.read().replace('\\n', '')\n",
    "\n",
    "with open('cnn-khashoggi.txt', 'r') as file:\n",
    "    text_cnn = file.read().replace('\\n', '')\n",
    "    \n",
    "stop_word = []\n",
    "with open(\"stop_words.csv\",mode='r') as file:\n",
    "    data = csv.reader(file)\n",
    "    for row in data:\n",
    "        stop_word.extend(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use a function to remove punctuation\n",
    "\n",
    "def remove_punctuation(value):\n",
    "    result = \"\"\n",
    "    for c in value: \n",
    "        if c not in string.punctuation:\n",
    "            result += c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We now define a function that splits the text strings into words\n",
    "\n",
    "def tokenize(text=None):\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text) ## This step removes all punctuations from the text string\n",
    "    text_list = text.split()\n",
    "    text_list2 = [word for word in text_list if word not in stop_word]\n",
    "    return text_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we need to count the number of occurance of each word\n",
    "\n",
    "def convert_text_to_dtm(txt):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in tokenize(txt):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a funtion that counts the number of occurances of each word in texts\n",
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM\n",
    "\n",
    "D = gen_DTM([text_alja,text_bbc,text_breit,text_fox,text_cnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = D.iloc[0].values\n",
    "x1 = D.iloc[1].values\n",
    "x2 = D.iloc[2].values\n",
    "x3 = D.iloc[3].values\n",
    "x4 = D.iloc[4].values\n",
    "x_total= [x0,x1,x2,x3,x4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function cosine to caltulate the cosine value\n",
    "def cosine(a,b):\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b))  )\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.679, 0.555, 0.658, 0.533],\n",
       "       [0.679, 1.   , 0.565, 0.606, 0.504],\n",
       "       [0.555, 0.565, 1.   , 0.518, 0.353],\n",
       "       [0.658, 0.606, 0.518, 1.   , 0.514],\n",
       "       [0.533, 0.504, 0.353, 0.514, 1.   ]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtain a cosine matrix (similarity)\n",
    "\n",
    "result = []\n",
    "for x in x_total:\n",
    "    for y in x_total: \n",
    "        result.append(cosine(x,y).round(3))\n",
    "result\n",
    "result_dat = pd.Series(result)\n",
    "result_dat.values.reshape(5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the matrix, we can see that no pair of two between these five texts are highly similar. The highest similary is between aljazeera and bbc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since these reports are all about Turkish President Erdogan addressing the \n",
    "## murder of journalist Jamal Khashoggi.\n",
    "## I will also drop common words like Turkey, President, Erdogan, Journalist, Jamal, Khashoggi.\n",
    "\n",
    "stop_word1 = []\n",
    "with open(\"stop_words.csv\",mode='r') as file:\n",
    "    data = csv.reader(file)\n",
    "    for row in data:\n",
    "        stop_word1.extend(row)\n",
    "stop_word1.extend([\"turkey\",\"president\",'erdogan','journalist','jamal','khashoggi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update function\n",
    "def tokenize(text=None):\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text) ## This step removes all punctuations from the text string\n",
    "    text_list = text.split()\n",
    "    text_list3 = [word for word in text_list if word not in stop_word1]\n",
    "    return text_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recycle other process\n",
    "def convert_text_to_dtm(txt):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in tokenize(txt):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM\n",
    "\n",
    "D = gen_DTM([text_alja,text_bbc,text_breit,text_fox,text_cnn])\n",
    "x0 = D.iloc[0].values\n",
    "x1 = D.iloc[1].values\n",
    "x2 = D.iloc[2].values\n",
    "x3 = D.iloc[3].values\n",
    "x4 = D.iloc[4].values\n",
    "x_total= [x0,x1,x2,x3,x4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.651, 0.516, 0.572, 0.431],\n",
       "       [0.651, 1.   , 0.513, 0.538, 0.407],\n",
       "       [0.516, 0.513, 1.   , 0.471, 0.279],\n",
       "       [0.572, 0.538, 0.471, 1.   , 0.35 ],\n",
       "       [0.431, 0.407, 0.279, 0.35 , 1.   ]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = []\n",
    "for x in x_total:\n",
    "    for y in x_total: \n",
    "        result1.append(cosine(x,y).round(3))\n",
    "result1\n",
    "result1_dat = pd.Series(result1)\n",
    "result1_dat.values.reshape(5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing soem common words, comparing with the matrix above, we can see that the similarity dropped significantly while the similarity between aljazeera and bbc is still the highest. The lowest similarity, in this case, happens between breitbart and cnn, which has a cos value of 0.279."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
